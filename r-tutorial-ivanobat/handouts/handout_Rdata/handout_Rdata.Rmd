---
title: "Data manipulation with R"
author: "Jordi Llorens^[I am truly indebted to Hrvoje Stojic, who originally created these materials for several offerings of the brush-ups in Data Science. The current handout is a re-adaptation of those.]"
date: "September, 2020"
output: 
  html_document:
    theme: united
    highlight: kate
    md_extensions:  +raw_tex+multiline_tables
    toc: true
    toc_depth: 2
  pdf_document:
    fig_caption: no
    highlight: kate
    keep_tex: no
    number_sections: yes
fontsize: 12pt
---

```{r, knitr_options, include=FALSE}
    
     # loading in required packages
    if (!require("knitr")) install.packages("knitr"); library(knitr)
    if (!require("rmarkdown")) install.packages("rmarkdown"); library(rmarkdown)

    # some useful global defaults
    opts_chunk$set(warning=FALSE, message=FALSE, include=TRUE, echo=TRUE, cache=FALSE, cache.comments=FALSE, comment='##')

    # output specific defaults
    output <- opts_knit$get("rmarkdown.pandoc.to")
    if (output=="html") opts_chunk$set(fig.width=10, fig.height=5)
    if (output=="latex") opts_chunk$set(fig.width=6,  fig.height=4,
        dev = 'cairo_pdf', dev.args=list(family="Arial"))
```


# Data import/export  

It is evident that before performing any analysis in R you need to import the data of interest. But data come in many different formats, so you’ll have to adapt and learn. Luckily, R has a plethora of input options^[See R Data Import/Export at [cran.r-project.org/doc/manuals/r-release/R-data.pdf](https://cran.r-project.org/doc/manuals/r-release/R-data.pdf)], among them Excel files and databases. Through some useful packages, such as `foreign` or `xlsReadWrite`, many other data formats can be imported as well, such as SAS, SPSS or STATA. 

Before getting any data into R, it is advisable to create a data directory in your machine where to store it. We will use it as the working directory - the default path where R will look to when importing/exporting data. 


## Importing native .RData files

This is the simplest way, but usually datasets are not disseminated publicly in this format. You can use `load` function to load such a file. Word of caution. Be careful with loading such files, they might contain many R objects, some of them with same names that you have in your current working environment. If this is the case, when you load the file, objects with same names in your environment will be overwritten.

```{r}
load('data/mtcars.Rdata')
```

## Importing plain text files

One of the standard ways to exchange data (specially in organizations with a low IT profile) are plain text files. There are two paradigms for storing data tables in plain text files: **delimited text** and **fixed width**. In both cases they may or may not have a **header** (column names) and before importing you can explore its contents with a plain text editor or a spreadsheet program (except if the file is huge, some programs may not support too many gigabytes). 

In **delimited text files** the data columns are explicitly delimited, typically with `;`, `,` or a tabulator (coded as `\t`). You may find other characters as separators. The standard file is **CSV** (comma-separated values, `,`).

The function `read.table` can import most of the delimited files you will find. Some non-standard files may need other specific functions, or they might be simply too big. Here we cover only `read.table`.


Download the *Demographic data of census sections in Barcelona* from
BCN Open Data.^[[Link to data](http://opendata.bcn.cat/opendata/en/catalog/SOCIETAT_I_BENESTAR/taulamapscensal)] to your working directory. It contains demographic information for each census division. Inspect it with a plain text editor (if you cannot understand the headers look at their online description). This is an example of a standard import - it has a header row (column names) and the field separator is `;`. 

```{r}
## Import
censusBCN <- read.table("data/MAP_SCENSAL.csv", header = TRUE,
                        sep = ";")

## Translating headers into English
names(censusBCN)
names(censusBCN) <- c("Date", "Men", "CensusDivision",
    "Women", "AGE_0_14", "AGE_15_A_24", "AGE_25_A_64",
    "AGE_65_plus", "NATIONALS", "EUCommunity",
    "Overseas")

## Data summary
summary(censusBCN)

## Computing a new column: percent of senior
## citizens
censusBCN$percentSenior <- censusBCN$AGE_65_plus /
    (censusBCN$Men + censusBCN$Women)
summary(censusBCN$percentSenior)
```

Download the Aging Population file from the UK Open Data site to your working directory^[[opendata.s3.amazonaws.com/aging-population-2008.csv](http://opendata.s3.amazonaws.com/aging-population-2008.csv)]. Inspect it with a plain text editor, and you will see the key import characteristics - it has a header row (column names), the field separator is `,` , and some strings are quoted with double quotation marks. With this in mind we can import it.


```{r}
## Import
agingPopulation <- read.table("data/aging-population-2008.csv",
                              header = TRUE, 
                              sep = ",", 
                              quote = "\"")

## Rename last column
names(agingPopulation)
names(agingPopulation)[7] <- "PercentSeniors"

## Data summary
summary(agingPopulation)
sapply(agingPopulation, class)
```


**Fixed-width files** have no delimiter between columns, so you will need a description defining the width of each column. We will work out an example from the INE (Spanish statistical office): Survey on Human Resources in Science and Technology 2009.^[[ine.es/en/prodyser/microdatos_en.htm](http://ine.es/en/prodyser/microdatos_en.htm)] INE’s microdata (individual responses to surveys) are usually stored as fixed/width files accompanied with a metadata spreadsheet. Download both the raw data^[[ftp://www.ine.es/temas/recurciencia/micro_recurciencia.zip](ftp://www.ine.es/temas/recurciencia/micro_recurciencia.zip)] and its metadata^[[ftp://www.ine.es/temas/recurciencia/disreg_recurciencia.xls](ftp://www.ine.es/temas/recurciencia/disreg_recurciencia.xls)], and import it into R.

```{r}
## Metadata for the selected columns
RRHH09Widths <- c(6, 2, 4, 2, 4, 1, 4, 4, 4, 1,
                  1, 2, 2, 2, 2, 2, 1, 1)

RRHH09Names <-c("MUIDENT", "CCAARESI", "ANONAC",
                "CCAANAC", "CONTNACIM", "RELA", "CONTNAC1",
                "CONTNAC2", "CONTNAC3", "SEXO", "ESTADOCIVIL",
                "DEPEN5", "DEPEN18", "DEPENMAS", "NIVESTPA",
                "NIVESTMA", "NIVPROFPA", "NIVPROFMA")

## Fixed-width import function
fwfDataFrame <- read.fwf(file = "data/RRHH09.txt",
                         n = 100, 
                         widths = RRHH09Widths, 
                         col.names = RRHH09Names)

## Data summary
summary(fwfDataFrame)
```

We imported only a sample of the data (the first 100 rows and the first 18 columns). It is usually a good idea for an initial exploration of the data.


**Practice** fixed-width import. Import all the columns of the `RRHH09.txt` file (but only 1000 rows). You will have to look at the metadata for the column widths and names. Summarize the columns, in particular the labor market situation (SITLAB). Is the employment rate among respondents high? (decypher its code values reading the metadata).



## Exporting data

After any serious data analysis we might want to output its results. The most common function to export data in R is `write.table`. Not by chance, the name reminds of the import function `read.table`. If no folder is specified, the file will be saved at the working directory.

Before writing data into a plain text file, we must make decisions about its output format: the field separator string, whether to output the column and row names, whether to quote strings or not, or the decimal separator.

Let us see an example by exporting the `mtcars` data:

```{r}
# Typical csv export
write.table(mtcars, file = "data/mtcars.csv", sep = ",",
            quote = FALSE, row.names = FALSE)

# Custom export
write.table(mtcars, file = "data/mtcars.dat", sep = "\t",
            row.names = TRUE, dec = ",")
```

Saving in the native .RData file allows you to save multiple objects in any format, while saving in text files you are usually constrained to saving data frames. First argument specifies the object, second the name of the file to be saved.

```R
save(mtcars, file="mtcars.RData")
```

Same as with import, the packages like `foreign` and `xlsReadWrite` make it easy to export data in proprietary formats^[[statmethods.net/input/exportingdata.html](http://statmethods.net/input/exportingdata.html)], such as MS Excel, SPSS, SAS, or Stata.



# Transforming data

Transforming datasets and variables is essential in any data-oriented project. You will need, even for the most basic programming task, to select rows from a data frame or to merge two data sets.


## Subsetting in more details

When we introduced data frames we already saw how to select specific parts of a data set (given certain conditions). We will refresh the basics and dig a little deeper.

Subsetting in data frames uses indices on rows/columns: `[optional
rows condition, optional columns condition]`. Note that you can use negative numbers to indicate that the rows/columns with those indices should be *removed*.

```{r, include=FALSE}
mtcars[c(1, 3, 5), ]
mtcars[-c(1, 3, 5), ]
mtcars[, c(1, 3, 5)]
mtcars[, -c(1, 3, 5)]
```

Logical conditions are very often used to subset the data. The idea is to produce a logical vector whose length will be the same as the number of rows (if we want to subset according to rows) or the number of columns. Then, those rows indicated with `TRUE` will be produced as an output of subsetting. We have following **logical operators** that we can use in R: `<`, `>`, `<=`, `>=`, `!=` and `==`. 

```{r}
# Logical conditions on data frame values
mtcars[mtcars$hp > 200, ][1:5,]
mtcars[mtcars$cyl == 6, ][1:5,]
mtcars[mtcars$cyl != 6, ][1:5,]
```

Note that the second brackets are there simply to shorten the output to the first 5 lines. Multiple conditions can be connected with **logical expressions**: `!`, `&`, `&&`, `|`, `||` and `xor` function. Inputs to these functions need to be logical vectors.

```{r}
# Multiple conditions on data frame values
mtcars[mtcars$hp > 200  & mtcars$mpg > 14, ]
mtcars[mtcars$hp >= 250 | mtcars$hp <= 65, ]
```

Conditions on both rows and columns.

```{r}
mtcars[row.names(mtcars) %in% c("Fiat 128", "Fiat X1-9"),
       c("mpg", "cyl", "wt")]
```

Conditions using functions.

```{r}
mtcars[substr(row.names(mtcars), 1, 4) == "Fiat",
c("mpg", "cyl", "wt")]
mtcars[mtcars$hp == max(mtcars$hp), ]
```

Using the library `data.table`, you can invoke the function `like` for doing partial matching comparisons:
```{r}
if(!require(data.table)) install.packages('data.table') else library(data.table)
'Fiat' %like% 'Fiat1' # this is FALSE
'Fiat1' %like% 'Fiat' # this is TRUE
mtcars[row.names(mtcars) %like% 'Fiat',]
```


Using stored conditions.

```{r}
hpPattern <- mtcars$hp >= 250 | mtcars$hp <= 65
mtcars[hpPattern, ]
```



## Sorting

Sorting a vector:

```{r}
sort(mtcars$hp, decreasing = TRUE)
```

The subsetting notation can be also used for sorting data frames using the `order` function:

```{r}
mtcars[order(mtcars$hp), ][1:5,]
mtcars[order(mtcars$hp, decreasing = TRUE), ][1:5,]
```

Ordering by multiple columns is straightforward (for clarity, we first store the row conditions on a vector):

```{r}
# Index of sorted rows
hpOrder <- order(mtcars$hp, mtcars$mpg, decreasing = TRUE)

# Using the stored order conditions
mtcars[hpOrder, ][1:5,]
```


## Appending

To combine vectors you have already seen that you can use `c` function. We have used it until now to create atomic vectors, but depending on the objects you are combining, the output might be a list. 

```{r}
# combining objects in a vector
c(mtcars[1,1], mtcars[1,3])  # atomic vector
c(mtcars[1,1], mtcars[1:3,1:3])  # list
```

Binding together several data frames with a common structure is easy. To combine data frames column-wise and row-wise, you should use functions `cbind` and `rbind`.

```{r}
# combining data frames
cbind(mtcars[,1], mtcars[,3])[1:5,]
rbind(mtcars[1:2,], mtcars[5:6,])
```

Be careful with the **broadcast** feature of R. Usually it is very useful, and you do not even notice it is at work, however, at other times, if you are not careful it can produce an undesired output that you will not notice - R will not show any warning as it assumes you know what you are doing.

```{r}
# broadcasting allows hand abbreviations such as
x <- matrix(NA, 4, 4)

# instead of
matrix(rep(NA,16), 4, 4)

# comes handy in creating data frames
cbind(1, x)

# however, here it will broadcast y to fill out the structure
# if this was not an intention, it will be difficult
# to detect an error
y <- c(1,2)
cbind(y, x)
```


**Practice** ordering, subsetting, appending. Order the mtcars data frame by ascending number of carburators and weight, create two data frames with the top 3 and bottom 3 rows according to this order, append them both.


## Merging

Adding data from a data frame to another data frame using some joining condition is an essential operation when manipulating data, because most information is stored in tables that relate to each other by some common identifier. A function that should be used for this purpose is `merge`. 


```{r}
authors <- data.frame(
     surname = I(c("Tukey", "Venables", "Tierney", "Ripley", "McNeil")),
     nationality = c("US", "Australia", "US", "UK", "Australia"),
     deceased = c("yes", rep("no", 4)))

books <- data.frame(
     name = I(c("Tukey", "Venables", "Tierney",
              "Ripley", "Ripley", "McNeil", "R Core")),
     title = c("Exploratory Data Analysis",
               "Modern Applied Statistics ...",
               "LISP-STAT",
               "Spatial Statistics", "Stochastic Simulation",
               "Interactive Data Analysis",
               "An Introduction to R"),
     other.author = c(NA, "Ripley", NA, NA, NA, NA,
                      "Venables & Smith"))

merge(authors, books, by.x = "surname", by.y = "name")
```


## Variable transformations

We have already seen how to create new variables from existing ones. Here we will look at some special (and useful) cases:

Sometimes you need to transform a numerical variable into a categorical one. For example, divide horsepower into 2 categories: low (below average) and high (above average).

A naive approach would be:

```{r}
# Replicate the data frame (for keeping the
# original data unchanged)
mtcarsBis <- mtcars

# Create the above- and below-average bins
mtcarsBis$hpCateg[mtcarsBis$hp < mean(mtcarsBis$hp)] <- "Low"
mtcarsBis$hpCateg[mtcarsBis$hp >= mean(mtcarsBis$hp)] <- "High"
```

A more sophisticated way:

```{r}
mtcarsBis$hpCateg <- ifelse(test = mtcarsBis$hp >
mean(mtcarsBis$hp), yes = "Low", no = "High")
```

Binning numerical variables into more than 2 categories could be tedious following the previous examples, but the `cut` function clears the way.

**Practice**: binning into multiple categories with `cut` function. Bin horsepower (from the mtcarsBis dataset) into 4 categories using the `cut` function. Add a new column to the dataset with this categorical values.


# Data display

The first thing to do when having data at hand data is exploring it. We use the dataset `mtcars`, one of the several pre-loaded datasets in R, as an introductory example.^[[stat.ethz.ch/R-manual/R-devel/library/datasets/html/mtcars.html](http://stat.ethz.ch/R-manual/R-devel/library/datasets/html/mtcars.html)]

First we must make sure the import process was successful (check the number of rows and columns, make sure the numeric fields are not imported as strings, etc.).

```{r}
class(mtcars)
str(mtcars)
dim(mtcars)
names(mtcars)
summary(mtcars)
sapply(mtcars, class)
```

Then we can inspect visually our table. Since most of our tables have many more rows than our screens can show we start by looking at the top and bottom rows.

```{r}
head(mtcars)
tail(mtcars)

# you can specify the number of rows
head(mtcars, 10)  

```

After this visual inspection we can describe individual columns, summary tables for categorical data, histograms and descriptive statistics for numeric data, etc.




# Basic graphics  

Visualizing results for your analysis is critical for its success - conveying the right message). R is extraordinary powerful at graphing data, allowing a great degree of personalization and having several state-of-the-art packages.

We will start with the basics^[[statmethods.net/graphs/density.html](http://statmethods.net/graphs/density.html)], and later on we will use `ggplot2` - the package for advanced plotting in R.


**Stripcharts** are one-dimensional scatter plots and provide a (somewhat simplistic) first look at univariate series. Note the optional parameter `xlab` for setting the X-axis title.

```{r, fig.margin=TRUE, fig.cap="Stripchart: first look at mpg."}
stripchart(mtcars$mpg, xlab = "Miles per gallon")
```

A **histogram** cuts series in discrete bins, while a continuous distribution varies smoothly along the series. Histogram of mileage in the `mtcars` dataset.

```{r, fig.margin=TRUE, fig.cap="Histogram of mileage."}
hist(mtcars$mpg, main = "")
```

The default number of bins may be misleading, we can set more bins (maybe after some trial and error). Using the optional parameter `col` (setting the fill color for the histogram bins) helps focusing on the important message - the distribution.

```{r, fig.margin=TRUE, fig.cap="Smoother histogram of mpg."}
hist(mtcars$mpg, col = "gray", breaks = 10, main = "")
```

The **kernel density** estimate is a hypothetical continuous distribution generating a univariate series and provides a smooth approximation for the actual distribution. Kernel density estimates are closely related to histograms, but can be endowed with properties such as smoothness or continuity by using a suitable kernel.

Note we must first compute the estimated density with the `density` function.

```{r, fig.margin=TRUE, fig.cap="Density estimate of mileage."}
# Compute the density data
d <- density(mtcars$mpg)  

# Graph the results
plot(d, main = "")
```

**Boxplots** summarize univariate series in a single plot (including the range of the variable, its quartiles, and its outliers).^[[statmethods.net/graphs/boxplot.html](http://statmethods.net/graphs/boxplot.html)] In future lectures we will dig deeper on summarizing distributions. Here we will only plot the classical boxplot, grouping by the number of cylinders.

```{r, fig.margin=TRUE, fig.cap="Example of boxplot summary, car milage data"}
boxplot(mpg ~ cyl, data = mtcars, ylab = "MPG",
        xlab = "Number of Cylinders",
        names = c('cyl = 4', 'cyl = 6', 'cyl=8'),
        notch = T,
        plot = F)
```

**Scatterplots** display values for two variables for a set of data, and are essential when looking for relationships between them (e.g. linear correlation). In R the simplest way to plot them is the `plot` function, where we can also add a regression line.

```{r, fig.margin=TRUE, fig.cap="Hp vs weight: scatterplot and linear regression"}
# Scatterplot
plot(x = mtcars$hp, y = mtcars$wt, ylab = "Horsepower",
     xlab = "Weight (lb/1000)", pch = 16, col='black' )

# Linear regression line
abline(lm(wt ~ hp, data=mtcars), col = "red")
```

**Practice** describing BCN census data. Use the Demographic data of census sections in Barcelona we imported earlier and ...

1. produce stripcharts, histograms and kernel density estimates of a variable of your choice. Be creative: define a new variable combining existing ones, combine colors, explore optional parameters of the functions.  
2. scatterplot two variables and add a linear regression line. Try adding a loess regression curve. Choose appropriate point characters and point dimensions (with lots of data points maybe blank-filled smaller dots are most convenient).  
3. challenging bit: use the layout function to display all the univariate plots in a single matrix of plots.

```{r}
#1
censusBCN$women2men_ratio <- censusBCN$Women / censusBCN$Men 
stripchart(percentSenior ~ Men, data=censusBCN[1:100,],col='blue')
hist(censusBCN$women2men_ratio, col='darkblue',main=NULL,xlab='% Senior',freq=F)
# 2 
plot(censusBCN$percentSenior ~censusBCN$Men, 
     pch=19, 
     cex=1,
     col='darkblue',
     xlab='Men',
     ylab='% Senior')
abline(lm(percentSenior~Men,data=censusBCN),col='darkred')
# add local polynomial regression
x <- censusBCN$Men[order(censusBCN$Men)]
y <- loess(percentSenior~Men,data=censusBCN)$fitted[order(censusBCN$Men)]
lines(x=x, y=y, col='darkorange',pch=19,cex=1)
```


## A full example of a customized plot

Plotting data in R is always easy, but obtaining the format you need almost never is. Some packages will make your life easier, but you need to learn the basics of plot personalization. This is another powerful R feature.

Say we want to plot the miles per gallon of the `mtcars` data set. It is pretty straightforward.

```{r, fig.fullwidth=TRUE, fig.cap="A first attempt plotting miles per gallon.", fig.height=3.5}
plot(mtcars$mpg)
```

But you will agree it is also disappointing - bad axis titles, no main title, no identification of each car etc. But these flaws are also strengths. Plots are objects as any other and all the elements can be personalized and coded. This way, they can be reproduced when data change or if you share your code.


```{r, fig.fullwidth=TRUE, fig.cap="Our second attempt.", fig.height=3.5}
plot(mtcars$mpg, 
     main = "Miles per gallon for selected cars",
     ylab = "mpg", 
     pch = 16, 
     cex = 0.8, 
     ylim = c(0,max(mtcars$mpg))
    )
```

Now we have fixed some of these issues: `main` and `ylab` improve titles, `pch` and `cex` improve formats, `ylim` lets us set the axis limits. But the X axis remains without the proper car labels. Let us fix that too.

```{r, fig.fullwidth=TRUE, fig.cap="Now the X axis is informative.", fig.height=3.5}
plot(mtcars$mpg, 
     main = "Miles per gallon for selected cars", 
     ylab = "mpg", 
     pch = 16, 
     cex = 0.8, 
     ylim = c(0, max(mtcars$mpg)), 
     xaxt = "n", 
     xlab = "")

axis(side = 1, 
     at = seq_along(mtcars$mpg), 
     labels = rownames(mtcars), 
     las = 2, 
     cex.axis = 0.7)
```

With the axis function we can control the position and content of the axes (here the X axis, or side=1).

Maybe adding vertical gridlines will help identifying each car, and
coloring according to the cylinders may be informative.

```{r, fig.fullwidth=TRUE, fig.cap="Finally a plot both informative and well formatted.", fig.height=3.5}
plot(mtcars$mpg, 
     main = "Miles per gallon for selected cars", 
     ylab = "mpg", 
     pch = 16, 
     cex = 0.8, 
     ylim = c(0, max(mtcars$mpg)), 
     xaxt = "n", 
     xlab = "",
     col = mtcars$cyl)

axis(side = 1, 
     at = seq_along(mtcars$mpg), 
     labels = rownames(mtcars), 
     las = 2, 
     cex.axis = 0.7)

abline(v = seq_along(mtcars$mpg), 
       col = "gray", 
       lty = 2)

legend(x = "bottomleft", ncol = 3, cex = 0.6,
       bg = "white", 
       legend = c("4 cyl", "6 cyl", "8 cyl"), 
       text.col = "azure4", 
       col = c(4, 6, 8), pch = 16)
```

Changing fonts is a bit more tricky. Moreover, R by default uses Helvetica font in figures and these fonts are not necessarily available everywhere as it is a commercial font. Hence, some pdf readers might not render correctly the figures. See `extrafont` package for some extra options with fonts.


## Saving plots

By default, a plot in R opens a device in your desktop (or within RStudio). But usually you will need to save it as a high-quality image. R allows different output formats for graphics (pdf, jpg, png). Here we will set an example of pdf output.

```R
## Open the device
pdf("mileage.pdf", width = 10, height = 2.5)

## Add the plot
plot(mtcars$mpg)
abline(h = mean(mtcars$mpg), 
       col = "lightgray",
       lty = 2)

## Close the device
dev.off()
```

Note that no directory path is specified. By default, the file will be saved at the current working directory, optionally you can set a different output directory.



# Basic text manipulation  

In almost every analysis you need to perform operations on dates and text strings. Here we will take a look at the essential operations on these types of data.

Handling strings in R can sometimes be painful.^[A classical reference for handling text is: Sanchez, G. (2013) Handling and Processing Strings in R. Trowchez Editions. Berkeley. [gastonsanchez.com/Handling_and_Processing_Strings_in_R.pdf](http://gastonsanchez.com/Handling_and_Processing_Strings_in_R.pdf)] Several packages exist that ease this pain. Here we look only at R base functions.

The `paste` function is perhaps the most used in R when handling strings. It essentially concatenates strings, but in a generalized way (e.g. you can choose the character separating strings, or it converts non-string objects to characters). By default, it concatenates strings separating them with a blank space.

```{r}
paste("Barcelona", "GSE")
```

The sep parameter sets a different separator. The `paste0` function is a convenient alternative when you don't want any form of separation, so it is as if you set `sep = ""`.

```{r}
paste("Barcelona", "GSE", sep = "-")
paste0("Barcelona", "GSE")
```

Numeric variables are coerced to strings.

```{r}
paste("The Life of", pi)
```

You can also operate with vectors.

```{r}
paste("Class of 201", 4:7, sep = "")
```

Count number of characters: `nchar` function works both with a single string or with a vector.

```{r}
nchar(c("How", "many", "characters?"))
nchar("How many characters?")
```

Convert to lower/upper case with `tolower` and `toupper` functions. Again, they also work on vectors.

```{r}
tolower("Barcelona GSE")
toupper(c("Barcelona", "GSE"))
```

Obtain and replace substrings with `substr` function.

```{r}
substr("Barcelona GSE", start = 11, stop = 13)
days <- c("Mond", "Tues", "Wedn")
substr(days, 4, 4) <- "."
days
```

Character translation with `chartr`.

```{r}
chartr(old = "4", new = "a", "B4rcelon4 GSE")
chartr(old = "410", new = "aio", 
       "B4rcel0n4 Gr4du4te Sch00l of Ec0n0m1cs")
```

Uniquely abbreviate strings with `abbreviate`.

```{r}
abbreviate(c("Asset Pricing", "Corporate Finance",
             "Econometrics"), minlength = 5)
```

**Practice** character to numeric when importing. The Aging Population data imported earlier has some numerical columns stored as character. Use basic string manipulations to convert them back into numerical.^[Hint: define new columns for trial and error.]

```{r}
agingPopulation$Total.Population <- 
  as.numeric(gsub(',','',agingPopulation$Total.Population))
agingPopulation$PercentSeniors <- 
  as.numeric(gsub('%','',agingPopulation$PercentSeniors))
```


# Dates and times in R

Dates are represented as the number of days since 1970-01-01, with negative values for earlier dates. But R outputs them with the familiar formats (e.g. MMDDYYY). Converting to/from dates and operating with them requires some familiarity with the main R date formats and functions.^[[en.wikibooks.org/wiki/R_Programming/Times_and_Dates](http://en.wikibooks.org/wiki/R_Programming/Times_and_Dates)] There are packages like `lubridate` that facilitate handling of dates and time.


**System date and time** are useful for many purposes (e.g. computing execution times, saving files with dynamical names).

```{r}
# System date with default format
Sys.time()  

# Time with HH:MM:SS format
format(Sys.time(), "%H:%M:%S") 

# Date with YYYYMMDD format
format(Sys.time(), "%Y-%m-%d") 

# using system time for measuring difference
x <- Sys.time()
y <- Sys.time()
y - x

# there is a specific function for that
system.time(
    for(i in 1:100) mad(runif(1000))
)
```

Output of `system.time` might be confusing. **User CPU time** gives the CPU time spent by the current R session, while **system CPU time** gives the CPU time spent by the operating system on behalf of the R session. The operating system might do additional other operations like opening files, doing input or output, starting other processes, and looking at the system clock, operations that involve resources that many processes must share. **Elapsed time** is the sum of the two.

Converting strings to date/time objects is the name of the game when importing data files. Being familiar with date conversion and formatting is also crucial when reporting results. Some examples.


```{r}
# Input date format
x <- as.Date("20140912", format = "%Y%m%d")
x 
class(x)
typeof(x)

# Input time and date
strptime("09/12/11 17.30.00", format = "%m/%d/%y %H.%M.%S")

# convert to string
as.character(Sys.time())
```

**Extracting information from dates.**

```{r}
# Name of weekday
weekdays(Sys.time())

# Name of month
months(Sys.time()) 

# Number of days since beginning of epoch
julian(Sys.time()) 
```

Julian Day Number (JDN)^[[en.wikipedia.org/wiki/Julian_day](http://en.wikipedia.org/wiki/Julian_day)] is the number of days since noon UTC on the first day of 4317 BC.

**Generating sequences of dates**

```{r}
seq(from = as.Date("2014-09-12"), 
    to = as.Date("2014-09-14"),
    by = "day")

# All days between two dates
seq(from = as.Date("2014-09-12"), 
    to = as.Date("2014-11-12"),
    by = "month")

# All months between two dates
seq(from = as.Date("2014-09-12"), 
    to = as.Date("2014-09-16"),
    length.out = 3)

# Every other day between two dates
# Next 3 days
seq.Date(Sys.Date(), length = 3, by = "1 days")

# Next 3 months
seq.Date(Sys.Date(), length = 3, by = "1 months")
```

Operations with dates.

```{r}
# Number of days since a given date
julian(Sys.time()) - julian(as.Date("2014-01-01"))

# Adding days
as.Date("2014-09-12") + 30

# Adding months
seq.Date(Sys.Date(), length = 2, by = "3 months")[2]
```

**Practice** proper formatting of dates in imported data. Create a new column in the BCN census data containing the day after the first column date. You must use the `as.Date` function.

# Time Series in R

Manipulating Time Series in R with what we have learnt so far is possible.
However, the powerful package **eXtensible Time Series** `xts` can make our lives a lot easier. **xts** objects are simple, we just have to think of them as matrices of observations combined with an index of corresponding dates and times. To create an `xts` object, we just need to have a vector/matrix of observations and an index vector (date format) with the same length:

```{r}

# Load xts
if (!require(xts)) install.packages('xts') else library(xts)

# Generate normally distributed data
set.seed(42)
data <- data.frame(x=rnorm(5))

# Create dates as a Date class object (they can be irregularly spaced!)
dates <- as.Date(c("2020-01-01","2020-02-03",
                   "2020-05-10","2020-06-01",
                   "2020-07-31"))
# Create xts object
X <- xts(x = data, order.by = dates) 

# Plot xts object
plot(X, type='b',ylim=c(-1,2))

# Given an xts, it is also easy to extract the core data and the index 
# in case you want to deal with them separately
class(coredata(X))
class(index(X))
```

One major difference between xts and most other time series objects in R is the ability to use any one of various classes that are used to represent time. Whether POSIXct, Date, or some other class, xts will convert this into an internal form to make subsetting as natural to the user as possible.

```{r}
# Create dates
dates <- as.Date("2016-01-01") + 0:4

# Create ts_a with a Date object
ts_a <- xts(x = 1:5, order.by = dates)

# Create ts_b with POSIXct object
ts_b <- xts(x = 1:5, order.by = as.POSIXct(dates))

# Extract the rows of ts_a using the index of ts_b
ts_a[index(ts_a)]

# Extract the rows of ts_b using the index of ts_a
ts_a[index(ts_b)]
```

## Importing data to xts
```{r}
tmp_file <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_1127/datasets/tmp_file.csv"

# Create dat by reading tmp_file using read.csv
dat <- read.csv(tmp_file)

# Convert dat into xts
dat_xts <- xts(dat, order.by = as.Date(rownames(dat), "%m/%d/%Y"))

# Alternative: use read.zoo and convert to xts
dat_zoo <- as.xts(read.zoo(tmp_file, index.column=0, sep=',', format='%d/%m/%Y'))
```

## Exporting xts

If you are working exclusively in R, the most convenient way to export/import xts objects is by use of the `saveRDS()` and `readRDS()` functions. Of course, you could use `save()` but this is different since it saves the object with the name in the current environment, whereas `saveRDS()` just saves a representation of the object. 
```{r}
f <- 'data/dat_zoo.rds'
saveRDS(object = dat_zoo, file = f)
class(readRDS(f))
```

But sometimes you find yourself needing to share results with others, often expecting data 
to be consumed by processes unaware of R and xts. 
In that case, one of the best ways to write an xts object from R is to use the zoo function
`write.zoo`. In this brief exercise we will convert sunspots to xts and save it as sunspots_xts. 

```{r}
# Get pre-loaded data and inspect the class
data(sunspots)
class(sunspots)

# Convert sunspots to xts using as.xts().
sunspots_xts <- as.xts(sunspots)
plot(sunspots_xts)
# Get the temporary file name
tmp <- tempfile()

# Write the xts object using zoo to tmp 
write.zoo(sunspots_xts, sep = ",", file = tmp)

# Read the tmp file. FUN = as.yearmon converts strings such as Jan 1749 into a proper time class
sun <- read.zoo(tmp, sep = ",", FUN = as.yearmon)

# Convert sun into xts. Save this as sun_xts
sun_xts <- as.xts(sun)
```
## Extracting data 

Extracting data is intuitive with xts objects. 
You can use the same indexing techniques as with matrices, and more. 
For instance, consider the following examples:

```{r}
# Extract first two observations
X[1:2]
# Extract date '2020-06-01'
X['2020-06-01']
# Extract year '2020'
X['2020']
# Extract only January and February data:
X['202001/202002']
# Extract data from a given vector of dates
dates <- c('2020-05-10','2020-07-31')
X[dates]
# Extract first and last two months
first(X, "2 months")
last(X, "2 months")
````

Also it is possible to merge xts objects by date, combine rows/columns as with a data.frame structure,
take differences in the data, lags, and many other convenient functions for time series analysis.

# Data Wrangling with dplyr

A package which is definitely worth exploring for data manipulation is `dplyr`.
To illustrate, we use the `flights` dataset from the `nycflights13` package.

```{r message=FALSE, include=FALSE}
avpacks <- available.packages(repos ="http://cran.us.r-project.org")
avpacks <- avpacks[,'Package']
packs <- c('nycflights13','dplyr')
if (!all( packs %in% avpacks )){
  install.packages( packs[ packs %in% avpacks ],
                    repos = "http://cran.us.r-project.org")
  } else {
  sapply(packs,library,character.only=TRUE)
  }
```

```{r}
head(flights,5)
```
The `dplyr` package has a `filter()` function 
(note that when loading the package, the `filter()` function from the `stats` package is masked) which we can use as follows. Say we would like to get only the flights that happened in November or December, which arrived more than two hours late, but did not leave late. Then,

```{r}
filter(flights, 
       month %in% c(11,12), 
       dep_delay <= 0,
       arr_delay > 120)
```
Another useful command is the pipe operator `%>%`.
It allows us to perform different manipulations sequentially, 
taking the output from the last operation as the input for the next one:

```{r}
flights %>% 
  filter(month %in% c(11,12),
         dep_delay <= 0,
         arr_delay > 120) %>%
  select(year,month,day,dep_delay,arr_delay)
```

A lot more can be done with this package. 
For instance, check out dplyr's cheat sheet ^[`dplyr` cheat sheet: https://rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf ]




